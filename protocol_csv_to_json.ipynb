{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f34df6-06ee-4c32-b8b8-89575de64fba",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62102e45-eede-453d-8268-d82ff7130b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Union\n",
    "import json\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166cb01-f4e9-4932-874f-755782c18c20",
   "metadata": {},
   "source": [
    "# Set Dir, Load Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57aa57a-2c79-46e1-a418-8b0ecdc56302",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions for detecting and correcting old JSONS, converting them to a CSV and back to JSON, and estimating protocol length from a group of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33ef69-76dc-4888-891c-4c2f4affd394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "# Function to load JSON from a file path\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def estimate_gesture_length(file_paths: List[str]) -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Estimate the length of each gesture in each JSON file.\n",
    "    \n",
    "    Parameters:\n",
    "        file_paths (List[str]): List of paths to the JSON files.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, List[float]]: A dictionary where keys are file names and values are lists of \n",
    "                                 estimated lengths for each gesture in that file, in minutes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty dictionary to hold the estimated lengths\n",
    "    estimated_lengths = {}\n",
    "\n",
    "    # Loop through each file to estimate gesture lengths\n",
    "    for file_path in file_paths:\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        json_data = load_json(file_path)\n",
    "        \n",
    "        if 'gests' in json_data:\n",
    "            file_lengths = []\n",
    "            for gest in json_data['gests']:\n",
    "                # Calculate the estimated length for the current gesture\n",
    "                rep_count = gest.get('repCount', 0)\n",
    "                duration = gest.get('duration', 0)\n",
    "                \n",
    "                total_duration_ms = rep_count * duration\n",
    "                total_duration_minutes = (total_duration_ms / 1000) / 60\n",
    "                \n",
    "                file_lengths.append(total_duration_minutes)\n",
    "            \n",
    "            estimated_lengths[file_name] = file_lengths\n",
    "\n",
    "    return estimated_lengths\n",
    "\n",
    "\n",
    "def csv_to_json_files(input_csv_path: str, output_folder: str, version: float) -> List[str]:\n",
    "    \"\"\"\n",
    "    Convert a CSV file back to individual JSON files, one for each test_number.\n",
    "    \n",
    "    Parameters:\n",
    "        input_csv_path (str): Path to the input CSV file.\n",
    "        output_folder (str): Folder where the output JSON files will be saved.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: List of paths to the generated JSON files.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    \n",
    "    if version == 0.54:\n",
    "        df.rename(columns={\n",
    "            'startStimulus': 'startInference',\n",
    "            'endStimulus': 'endInference',\n",
    "            'activeClass': 'name',\n",
    "        }, inplace=True)\n",
    "        \n",
    "    \n",
    "    # Initialize a list to hold the paths to the generated JSON files\n",
    "    output_file_paths = []\n",
    "    \n",
    "    # Group the DataFrame by test_number\n",
    "    grouped = df.groupby('test_number')\n",
    "    \n",
    "    for test_number, group in grouped:\n",
    "        # Extract unique values for the columns used to construct the file name\n",
    "        protocol_group = group['protocol_group'].iloc[0] if pd.notna(group['protocol_group'].iloc[0]) else ''\n",
    "        arm_posture = group['arm_posture'].iloc[0] if pd.notna(group['arm_posture'].iloc[0]) else ''\n",
    "        wrist_posture = group['wrist_posture'].iloc[0] if pd.notna(group['wrist_posture'].iloc[0]) else ''\n",
    "        hand_posture = group['hand_posture'].iloc[0] if pd.notna(group['hand_posture'].iloc[0]) else ''\n",
    "        body_activity = group['body_activity'].iloc[0] if pd.notna(group['body_activity'].iloc[0]) else ''\n",
    "        handedness = group['handedness'].iloc[0] if pd.notna(group['handedness'].iloc[0]) else ''\n",
    "        \n",
    "        # Construct the file name\n",
    "        file_name = f\"{test_number}-{protocol_group}-{arm_posture}-{wrist_posture}-{hand_posture}-{body_activity}-{handedness}.json\"\n",
    "        \n",
    "        # Create the JSON data structure\n",
    "        json_data = {\n",
    "            'name': file_name.split('.json')[0],  # Update the 'name' to match the file name\n",
    "            'gests': group.drop(['test_number', 'protocol_group', 'arm_posture', 'file_name', 'wrist_posture', 'hand_posture', 'body_activity', 'handedness'], axis=1).to_dict('records')\n",
    "        }\n",
    "        \n",
    "        # Save the JSON data to a file\n",
    "        output_file_path = os.path.join(output_folder, file_name)\n",
    "        with open(output_file_path, 'w') as f:\n",
    "            json.dump(json_data, f, indent=4)\n",
    "        \n",
    "        output_file_paths.append(output_file_path)\n",
    "    \n",
    "    return output_file_paths\n",
    "\n",
    "import shutil\n",
    "\n",
    "def rename_files_with_double_digit_test_number(input_folder: str, output_folder: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Rename files in a folder such that test numbers less than 10 are made double digits (e.g., 1 becomes 01).\n",
    "    \n",
    "    Parameters:\n",
    "        input_folder (str): Folder containing the files to be renamed.\n",
    "        output_folder (str): Folder where the renamed files will be saved.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: List of paths to the renamed files.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Initialize a list to hold the paths to the renamed files\n",
    "    renamed_file_paths = []\n",
    "    \n",
    "    # Loop through each file in the input folder\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if 'ipynb_checkpoints' not in file_name:\n",
    "            # Extract the test number from the file name\n",
    "            test_number = file_name.split('-')[0]\n",
    "\n",
    "            # Convert single-digit test numbers to double digits\n",
    "            if len(test_number) == 1:\n",
    "                test_number = f\"0{test_number}\"\n",
    "                \n",
    "                \"\"\"\n",
    "        \n",
    "        BUGGED WHEN TEST NUMBER EXISTS ELSEWHERE IN FILE NAME\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "            # Construct the new file name\n",
    "            new_file_name = file_name.replace(file_name.split('-')[0], test_number)\n",
    "\n",
    "            # Copy the file to the output folder with the new name\n",
    "            input_file_path = os.path.join(input_folder, file_name)\n",
    "            output_file_path = os.path.join(output_folder, new_file_name)\n",
    "            shutil.copy(input_file_path, output_file_path)\n",
    "\n",
    "            renamed_file_paths.append(output_file_path)\n",
    "    \n",
    "    return renamed_file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f432a94-2ec8-4b61-a6f2-47744f82c89f",
   "metadata": {},
   "source": [
    "# make changes based on differences between old and new JSONS and correct protocol_ids to be incremental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa236f-bc0e-4683-a050-c9e33c702d0d",
   "metadata": {},
   "source": [
    "# Convert the final CSV file back into JSON by test number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36fe4aa-134a-46bb-a26c-a0220f0c01ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the function with \n",
    "output_folder = 'new_json'\n",
    "output_file_paths = csv_to_json_files('defender.csv', output_folder, version = 0.54) # Enter corresponding csv file name in folder with script e.g. test.csv\n",
    "output_file_paths[:5]  # Show first 5 output file paths for verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8216b175-e805-4c48-b8e9-2a1e505c01c8",
   "metadata": {},
   "source": [
    "# make sure files can be sorted incrementally by replacing any single digita number with double digit (eg. 1 --> 01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23895b88-ffab-4877-8e64-241c4013dd24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the function with the existing output folder\n",
    "renamed_output_folder = 'final_json'\n",
    "renamed_file_paths = rename_files_with_double_digit_test_number(output_folder, renamed_output_folder)\n",
    "renamed_file_paths[:5]  # Show first 5 renamed file paths for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda12ed-c1c1-4a69-808a-fc2e232930ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = glob.glob(f'{renamed_output_folder}/*.json')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d5c7f-a107-441a-a61f-3f70eb7b70ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the function\n",
    "estimated_lengths = estimate_gesture_length(files)\n",
    "estimated_lengths\n",
    "\n",
    "# Calculate the total estimated length for the entire set of files\n",
    "total_length_minutes = sum(sum(lengths) for lengths in estimated_lengths.values())\n",
    "print(f' {total_length_minutes} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1233e6d-159c-4768-82cf-71584ebaa508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
