{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed738c3d-961c-408a-890f-67f2e8ed42e5",
   "metadata": {},
   "source": [
    "<h1> Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4471e27-8f65-4d57-a32c-6d7815e2dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" REQUIRES PISON CLOUD BINDINGS REPO IN LOCAL TREE WITH CODE IN WORKSPACE \n",
    "-- CODE SHOULD BE ADDED TO CHECK AGILITY AND FOCUS SESSIONS WHEN SESSION IDs GET ADDED AND USE FUTURE BULK DEVICE CONVERTER\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32da5e-3b31-4b7f-812a-4d633e34ff95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pandas_gbq\n",
    "import google.auth\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import grpc\n",
    "import logging\n",
    "import subprocess\n",
    "import google.auth.transport.requests\n",
    "import google.oauth2.id_token\n",
    "from abc import ABC\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import *\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "from scipy import signal\n",
    "from typing import List, Tuple, Union\n",
    "from scipy.signal import butter, iirnotch, filtfilt\n",
    "from google.protobuf.timestamp_pb2 import Timestamp\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "from google.auth import default\n",
    "\n",
    "#dag\n",
    "from pison_ml.processors.filtering import EMGButterNotchFilter\n",
    "from pison_ml.processors.filtering import EMGButterNotchFilterWide\n",
    "\n",
    "#proto\n",
    "import pison_cloud_bindings\n",
    "from pison_cloud_bindings.src import pison_cloud\n",
    "from pison_cloud.pison.common.cloud.v1.common_pb2 import ListQueryParameters\n",
    "from pison_cloud.pison.common.cloud.v1.common_pb2 import DateRange\n",
    "\n",
    "from pison_cloud.pison.session.cloud.v1 import session_pb2_grpc, session_pb2\n",
    "from pison_cloud.pison.session.cloud.v1.session_pb2 import ReadSessionRequest\n",
    "\n",
    "from pison_cloud.pison.authorization.cloud.v1.authorization_pb2_grpc import AuthorizationManagementServiceStub\n",
    "from pison_cloud.pison.authorization.cloud.v1 import authorization_pb2\n",
    "\n",
    "from pison_cloud.pison.readiness.cloud.v1.readiness_pb2_grpc import ReadinessServiceStub\n",
    "from pison_cloud.pison.readiness.cloud.v1 import readiness_pb2 \n",
    "from pison_cloud.pison.readiness.cloud.v1.readiness_pb2 import Readiness as ReadinessScoreProto, \\\n",
    "    ListReadinessRequest as ListReadinessScoreRequest, ListSortParams as ReadinessSortParams, ListPaginationParams as ReadinessPaginationParams\n",
    "\n",
    "from pison_cloud.pison.agility_score.cloud.v1.agility_score_pb2_grpc import AgilityScoreServiceStub\n",
    "from pison_cloud.pison.agility_score.cloud.v1 import agility_score_pb2 \n",
    "from pison_cloud.pison.agility_score.cloud.v1.agility_score_pb2 import AgilityScore as AgilityScoreProto, \\\n",
    "    ListAgilityScoreRequest, ListSortParams as AgilitySortParams, ListPaginationParams as AgilityPaginationParams\n",
    "\n",
    "from pison_cloud.pison.focus_score.cloud.v1.focus_score_pb2_grpc import FocusScoreServiceStub\n",
    "from pison_cloud.pison.focus_score.cloud.v1 import focus_score_pb2_grpc, focus_score_pb2\n",
    "from pison_cloud.pison.focus_score.cloud.v1.focus_score_pb2 import FocusScore as FocusScoreProto, \\\n",
    "    ListFocusScoreRequest, ListSortParams as FocusSortParams, ListPaginationParams as FocusPaginationParams\n",
    "\n",
    "from pison_cloud.pison.device.cloud.v1.device_pb2_grpc import DeviceServiceStub\n",
    "from pison_cloud.pison.device.cloud.v1 import device_pb2, device_pb2_grpc\n",
    "\n",
    "from pison_cloud.pison.protocol.cloud.v1.protocol_pb2_grpc import ProtocolServiceStub\n",
    "from pison_cloud.pison.protocol.cloud.v1 import protocol_pb2, protocol_pb2_grpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846b576-90b7-48ca-bf7d-41d89c4b31e8",
   "metadata": {},
   "source": [
    "<h1> Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693cdce-b818-4079-b3bd-f9849ae7b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class environment:\n",
    "    # select environment to pass to the various http call functions\n",
    "    def __init__(self):\n",
    "\n",
    "        list_of_envs = [\n",
    "            \"dev\",\n",
    "            \"staging\",\n",
    "            \"ops\"\n",
    "        ]\n",
    "\n",
    "        print(\"select environment:\")\n",
    "        for x, env in enumerate(list_of_envs):\n",
    "            print(str(x) + \":\" + env)\n",
    "\n",
    "        selected_env = int(input())\n",
    "\n",
    "        project_id = f'pison-{list_of_envs[selected_env]}'\n",
    "        env = list_of_envs[selected_env]\n",
    "        \n",
    "        if env == 'ops':\n",
    "            server_address = 'cloud.pison.io'\n",
    "        else:\n",
    "            server_address = f'{list_of_envs[selected_env]}.cloud.pison.io'\n",
    "        audience = f'pison-{list_of_envs[selected_env]}'\n",
    "        \n",
    "        dataset = 'pison_dataset'\n",
    "        table = 'sensor_data'\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"selected environment:\")\n",
    "        print(f'project_id: {project_id}')\n",
    "        print(f'env: {env}')\n",
    "        print(f'server_address: {server_address}')\n",
    "        print(f'audience: {audience}')\n",
    "        print(f'dataset: {dataset}')\n",
    "        print(f'table: {audience}')\n",
    "\n",
    "        self.project_id = project_id\n",
    "        self.env = env\n",
    "        self.server_address = server_address\n",
    "        self.audience = audience\n",
    "        self.dataset = dataset\n",
    "        self.table = table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a10b673-a7f1-4694-b941-ac15b0700254",
   "metadata": {},
   "source": [
    "<h3> Services "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb16c3-02a0-44f9-b6bd-ca201b81c5a5",
   "metadata": {},
   "source": [
    "<h4> Microservice Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef09f7-5315-46b0-b033-0f2fd17a0214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResponseConverter(ABC):\n",
    "    def __call__(self, response):\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "class UsersConverter(ResponseConverter):\n",
    "    def __call__(self, response):\n",
    "        try:\n",
    "            response_dict = MessageToDict(response)\n",
    "            data_f = pd.json_normalize(response_dict['users'])\n",
    "        except:\n",
    "            data_f = super().__call__(response)\n",
    "        return data_f\n",
    "    \n",
    "class ReadinessConverter(ResponseConverter):\n",
    "    \"\"\"\n",
    "    Converter for the `ListReadiness()` RPC call\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, readiness_res):\n",
    "        \"\"\"\n",
    "        Convert a reponse object to pandas dataframe\n",
    "        :param reponse: a reponse object\n",
    "        :type response: grpc response\n",
    "        :return: a dataframe object\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        response_dict = MessageToDict(readiness_res)\n",
    "        if \"scores\" in response_dict:\n",
    "            data_f = pd.json_normalize(response_dict[\"scores\"])\n",
    "            if \"onsetMoments\" in data_f:\n",
    "                data_f = data_f.explode(\"onsetMoments\")\n",
    "        else:\n",
    "            data_f = super().__call__(readiness_res)\n",
    "        return data_f\n",
    "\n",
    "\n",
    "class BulkyReadinessConverter(ResponseConverter):\n",
    "    \"\"\"\n",
    "    Converter for the `ListReadiness()` RPC call, assuming a\n",
    "    response that includes bulk user data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, readiness_res):\n",
    "        \"\"\"\n",
    "        Convert a reponse object to pandas dataframe\n",
    "        :param reponse: a reponse object\n",
    "        :type response: grpc response\n",
    "        :return: a dataframe object\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        dfs = []\n",
    "        for _, user_scores in readiness_res.scores_by_user.items():\n",
    "            for score in user_scores.scores:\n",
    "                flat_score = pd.json_normalize(MessageToDict(score))\n",
    "                if \"onsetMoments\" in flat_score:\n",
    "                    flat_score = flat_score.explode(\"onsetMoments\")\n",
    "                dfs.append(flat_score)\n",
    "        data_f = pd.concat(dfs)\n",
    "        return data_f\n",
    "\n",
    "\n",
    "class AgilityConverter(ReadinessConverter):\n",
    "    \"\"\"\n",
    "    Converter for the `ListAgilityScore()` RPC call\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class BulkyAgilityConverter(BulkyReadinessConverter):\n",
    "    \"\"\"\n",
    "    Converter for the `ListAgilityScore()` RPC call, assuming a\n",
    "    response that includes bulk user data.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class FocusConverter(ReadinessConverter):\n",
    "    \"\"\"\n",
    "    Converter for the `ListFocusScore()` RPC call\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class BulkyFocusConverter(BulkyReadinessConverter):\n",
    "    \"\"\"\n",
    "    Converter for the `ListFocusScore()` RPC call, assuming a\n",
    "    response that includes bulk user data.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class BaselineConverter(ResponseConverter):\n",
    "    \"\"\"\n",
    "    Converter for the `ReadBaselineById()` RPC call\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, baseline_res):\n",
    "        \"\"\"\n",
    "        Convert a reponse object to pandas dataframe\n",
    "        :param reponse: a reponse object\n",
    "        :type response: grpc response\n",
    "        :return: a dataframe object\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        response_dict = MessageToDict(baseline_res)\n",
    "        data_f = pd.DataFrame(response_dict).T\n",
    "        return data_f\n",
    "\n",
    "\n",
    "class PlanConverter(ResponseConverter):\n",
    "    \"\"\"\n",
    "    Converter for the `ReadPlan()` RPC call\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, plan_res):\n",
    "        \"\"\"\n",
    "        Convert a reponse object to pandas dataframe\n",
    "        :param reponse: a reponse object\n",
    "        :type response: grpc response\n",
    "        :return: a dataframe object\n",
    "        :rtype: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        data = MessageToDict(plan_res)\n",
    "        if data and data[\"plan\"] and data[\"plan\"][\"stimuli\"]:\n",
    "            flat_data = {\n",
    "                \"timeInSeconds\": [],\n",
    "                \"configuration_color_red\": [],\n",
    "                \"configuration_color_green\": [],\n",
    "                \"configuration_color_blue\": [],\n",
    "                \"configuration_durationInSeconds\": [],\n",
    "            }\n",
    "\n",
    "            for stimulus in data[\"plan\"][\"stimuli\"]:\n",
    "                flat_data[\"timeInSeconds\"].append(stimulus[\"timeInSeconds\"])\n",
    "                config = stimulus[\"configuration\"]\n",
    "\n",
    "                for color in [\"red\", \"green\", \"blue\"]:\n",
    "                    val = config[\"color\"][color] if color in config[\"color\"] else 0.0\n",
    "                    flat_data[f\"configuration_color_{color}\"].append(val)\n",
    "\n",
    "                flat_data[\"configuration_durationInSeconds\"].append(config[\"durationInSeconds\"])\n",
    "\n",
    "            # Create DataFrame\n",
    "            data_f = pd.DataFrame(flat_data)\n",
    "        else:\n",
    "            data_f = super().__call__(plan_res)\n",
    "        return data_f\n",
    "    \n",
    "class SessionConverter(ResponseConverter):\n",
    "    def __call__(self, session_res):\n",
    "        try:\n",
    "            response_dict = MessageToDict(session_res)\n",
    "            data_f = pd.json_normalize(response_dict['sessions'])\n",
    "            if 'protocolExecutions' in data_f:\n",
    "                data_f = data_f.explode('protocolExecutions')\n",
    "\n",
    "            # Normalize the dictionaries in the 'col_with_dicts' column\n",
    "            normalized_column_df = pd.json_normalize(data_f['protocolExecutions'])\n",
    "\n",
    "            # Rename the columns of the normalized column DataFrame to include the original key name\n",
    "            renamed_columns = {}\n",
    "            for col in normalized_column_df.columns:\n",
    "                original_key = f\"{data_f['protocolExecutions'].name}.{col}\"\n",
    "                if original_key not in data_f.columns:\n",
    "                    renamed_columns[col] = original_key\n",
    "\n",
    "            normalized_column_df = normalized_column_df.rename(columns=renamed_columns)\n",
    "            \n",
    "            # Reset index due to overlapping indices on same session id with a different protocol\n",
    "            data_f.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # Merge the normalized DataFrame with the original DataFrame\n",
    "            data_f = pd.concat([data_f.drop(columns='protocolExecutions'), normalized_column_df], axis=1)\n",
    "        except:\n",
    "            data_f = super().__call__(session_res)\n",
    "        return data_f \n",
    "\n",
    "class ProtocolConverter(ResponseConverter):\n",
    "    def __call__(self, protocol_res):\n",
    "        try:\n",
    "            response_dict = MessageToDict(protocol_res)\n",
    "            data_f = pd.json_normalize(response_dict['protocols'])\n",
    "            data_f.rename(columns = {'id': 'protocol_id'}, inplace = True)\n",
    "        except:\n",
    "            data_f = super().__call__(protocol_res)\n",
    "        return data_f \n",
    "    \n",
    "class DeviceConverter(ResponseConverter):\n",
    "    def __call__(self, device_res):\n",
    "        try:\n",
    "            response_dict = MessageToDict(device_res)\n",
    "            data_f = pd.json_normalize(response_dict['device'])\n",
    "            data_f.rename(columns = {'id': 'device_uid', 'name': 'device.deviceId'}, inplace = True)\n",
    "        except:\n",
    "            data_f = super().__call__(device_res)\n",
    "        return data_f \n",
    "        \n",
    "class PisonGrpc:\n",
    "    def __init__(self, env_selection):\n",
    "        self._target = env_selection.server_address\n",
    "        self._audience = env_selection.audience\n",
    "        self._id_token = None\n",
    "        self._channel = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.create_channel()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        if self._channel is not None:\n",
    "            self._channel.close()\n",
    "\n",
    "    def create_channel(self):\n",
    "        request = google.auth.transport.requests.Request()\n",
    "        # self._id_token = google.oauth2.id_token.fetch_id_token(request, audience=self._audience)\n",
    "        \n",
    "        # Option 2: Using gcloud installed to your machine with account impersonation; useful if you are on a local machine without pantheon installed, but you have gcloud\n",
    "        #   Requires the following scopes requested from IT (bruno@pison.com)\n",
    "        #   \"Service Account User\" (roles/iam.serviceAccountUser)\n",
    "        #   \"Service Account Token Creator\" (roles/iam.serviceAccountTokenCreator)\n",
    "        SERVICE_ACCOUNT = f\"dashboard-service-account@pison-{env_selection.env}.iam.gserviceaccount.com\"\n",
    "        audience = self._audience\n",
    "        result = subprocess.run(\n",
    "            [f'gcloud auth print-identity-token --impersonate-service-account=\"{SERVICE_ACCOUNT}\" --audiences=\"{audience}\"'],\n",
    "            stdout=subprocess.PIPE,\n",
    "            shell=True,\n",
    "        )\n",
    "        self._id_token = result.stdout.decode(\"utf-8\")[:-1]  # remove trailing newline\n",
    "        \n",
    "        # Create a channel.    \n",
    "        self._channel = grpc.secure_channel(self._target, grpc.ssl_channel_credentials())\n",
    "\n",
    "    def __call__(self, service_stub, rpc_name, request, res_converter=None):\n",
    "        stub = service_stub(self._channel)\n",
    "        rpc = getattr(stub, rpc_name)\n",
    "\n",
    "        response = rpc(\n",
    "            request,\n",
    "            metadata=[\n",
    "                (\"authorization\", f\"Bearer {self._id_token}\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        ret = {\n",
    "            'response': response\n",
    "        }\n",
    "\n",
    "        if res_converter:\n",
    "            df = res_converter(response)\n",
    "            ret['dataframe'] = df\n",
    "\n",
    "        return ret\n",
    "\n",
    "    @staticmethod\n",
    "    def to_pb_timestamp(datetime):\n",
    "        timestamp = Timestamp()\n",
    "        timestamp.FromDatetime(datetime)\n",
    "        return timestamp\n",
    "    \n",
    "def get_protocol_by_id(env_selection, protocol_id):\n",
    "    with PisonGrpc(env_selection) as rpc:\n",
    "        try:\n",
    "            resp = rpc(protocol_pb2_grpc.ProtocolServiceStub, \"GetProtocol\", \n",
    "                       protocol_pb2.GetProtocolRequest(uuid = protocol_id, active = 3), \n",
    "                       ProtocolConverter())\n",
    "            return resp\n",
    "        except grpc.RpcError as e:\n",
    "            if settings.DEBUG:\n",
    "                raise\n",
    "            else:\n",
    "                capture_exception(e)\n",
    "    \n",
    "def get_all_protocols(env_selection):\n",
    "    with PisonGrpc(env_selection) as rpc:\n",
    "        resp = rpc(protocol_pb2_grpc.ProtocolServiceStub, \"GetProtocol\", \n",
    "                       protocol_pb2.GetProtocolRequest(), \n",
    "                       ProtocolConverter())\n",
    "        return resp\n",
    "\n",
    "def get_device_by_user_id(env_selection, user_id):\n",
    "    with PisonGrpc(env_selection) as rpc:\n",
    "        resp = rpc(device_pb2_grpc.DeviceServiceStub, \"ReadDevice\", \n",
    "                       device_pb2.ReadDeviceRequest(user_id = user_id), \n",
    "                       DeviceConverter())\n",
    "        return resp\n",
    "       \n",
    "def read_session(env_selection, session_id):\n",
    "    with PisonGrpc(env_selection) as rpc:\n",
    "        try:\n",
    "            resp = rpc(session_pb2_grpc.SessionServiceStub, \"ReadSession\", \n",
    "                           session_pb2.ReadSessionRequest(uuid=session_id), \n",
    "                           SessionConverter())\n",
    "            return resp\n",
    "        except grpc.RpcError as e:\n",
    "            if settings.DEBUG:\n",
    "                raise\n",
    "            else:\n",
    "                capture_exception(e)\n",
    "                \n",
    "def read_all_sessions(env_selection):\n",
    "    with PisonGrpc(env_selection) as rpc:\n",
    "        resp = rpc(session_pb2_grpc.SessionServiceStub, \"ReadSession\", \n",
    "                       session_pb2.ReadSessionRequest(), \n",
    "                       SessionConverter())\n",
    "        return resp\n",
    "            \n",
    "def get_plan_data(env_selection, score_df):\n",
    "    plans = []\n",
    "\n",
    "    with PisonGrpc(env_selection) as rpc:\n",
    "        for uid in tqdm(score_df.uid):\n",
    "            try:\n",
    "                plan_res = rpc(ReadinessServiceStub, \"ReadPlan\", \n",
    "                               readiness_pb2.ReadPlanRequest(uid=uid), \n",
    "                               PlanConverter())\n",
    "                this_df = plan_res['dataframe']\n",
    "                this_df['uid'] = uid\n",
    "\n",
    "                plans.append(this_df)\n",
    "            except Exception as ex:\n",
    "                #logging.error(ex, exc_info=True)\n",
    "                pass\n",
    "                \n",
    "    plan_df = pd.concat(plans)\n",
    "    return plan_df\n",
    "\n",
    "def get_pb_date_range(start, end):\n",
    "    return DateRange(start=datetime_to_timestamp(start), end=datetime_to_timestamp(end))\n",
    "\n",
    "def datetime_to_timestamp(datetime):\n",
    "    timestamp = Timestamp()\n",
    "    timestamp.FromDatetime(datetime)\n",
    "    return timestamp\n",
    "\n",
    "\n",
    "def timestamp_to_datetime(timestamp):\n",
    "    \"\"\"Converts Protobuf timestamp to date-aware datetime\"\"\"\n",
    "    return timestamp.ToDatetime(tzinfo=timezone.get_current_timezone())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e67ca8-d1a5-49fb-bb65-b8006366945e",
   "metadata": {},
   "source": [
    "<h2> Get Device Email Pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633773a2-78ac-4905-8872-43992ddf82b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query parameters\n",
    "start_date = '2024-03-01 00:00:00'\n",
    "end_date = '2024-03-25 23:59:59'\n",
    "session_id_list = [] # list strings of session ids or []\n",
    "protocol_list = [] # list of strings of protocols or []\n",
    "username = None # partial string of username or None\n",
    "limit = 1000000\n",
    "dt_start_date = datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")  # Convert string to datetime object\n",
    "dt_end_date = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\")  # Convert string to datetime object\n",
    "\n",
    "env_selection = environment()\n",
    "\n",
    "# Generate df of the session request from the API\n",
    "df_session_response = read_all_sessions(env_selection)['dataframe']\n",
    "df_session_response = df_session_response.rename(columns={'id':'session_id'})\n",
    "\n",
    "with PisonGrpc(env_selection) as rpc:\n",
    "        users_res = rpc(AuthorizationManagementServiceStub, \"ListUsers\", \n",
    "                        authorization_pb2.ListUsersRequest(), UsersConverter())\n",
    "\n",
    "all_user_df = users_res['dataframe'].dropna()\n",
    "\n",
    "# Change user list accordingly if another list is required\n",
    "# user_list_df = all_user_df[all_user_df.email.isin(user_of_interest)].reset_index(drop = True)\n",
    "user_df = all_user_df\n",
    "user_df = user_df.rename(columns={'uid':'userId'})\n",
    "try:\n",
    "    df_session_response = pd.merge(df_session_response, user_df, on='userId', how='left')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b2a70d-1831-4ca9-9037-f955b0aff2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_device_by_user_id(env_selection, 'dis8wInkIrT8YDPUkBUSo1frbcg1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68b0ec-e39a-443f-b826-1e46b8519dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "readiness_scores = []\n",
    "\n",
    "# Get Readiness Scores\n",
    "with PisonGrpc(env_selection) as rpc:\n",
    "    filter_params = ListQueryParameters(\n",
    "                user_ids=user_df['userId'],\n",
    "                date_range=get_pb_date_range(dt_start_date, dt_end_date)\n",
    "    )\n",
    "\n",
    "    request = ListReadinessScoreRequest(\n",
    "        query_parameters=filter_params,\n",
    "        sort=ReadinessSortParams(key='createdAt', ascending=False),\n",
    "        pagination=ReadinessPaginationParams(limit=limit, offset=0)\n",
    "    )\n",
    "\n",
    "    readiness_res = rpc(ReadinessServiceStub, \"ListReadiness\", request, BulkyReadinessConverter())\n",
    "    this_df = readiness_res['dataframe']\n",
    "    if this_df.shape[0] > 0:\n",
    "        readiness_scores.append(this_df)\n",
    "\n",
    "readiness_df = pd.concat(readiness_scores) if len(readiness_scores) > 0 else None\n",
    "readiness_df.reset_index(inplace=True, drop=True)\n",
    "df_readiness_full = pd.merge(readiness_df, user_df, on='userId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3b8c61-b510-4a8d-a7bc-b013c718f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all ready tests that don't have session ids i.e. ones performed with pison ready app\n",
    "df_ready_tests = df_readiness_full[df_readiness_full.sessionId.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e889adb-d78c-46d7-8567-80cc234bc89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "readiness_device_df = pd.DataFrame()\n",
    "# get_device_by_user_id(env_selection, 'Ay1z6J3uDaMpcdOkjNO4oxxStux2')['dataframe']\n",
    "for user_id in df_ready_tests.userId.unique():\n",
    "    try:\n",
    "        readiness_device_df = pd.concat([readiness_device_df, get_device_by_user_id(env_selection, user_id)['dataframe']])\n",
    "    except:\n",
    "        print(f'{user_id} failed')\n",
    "        continue\n",
    "        \n",
    "readiness_device_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5922e-f6d1-4a9e-aaa3-4ee18acb14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_df = pd.merge(readiness_device_df, df_ready_tests, on=['userId'], how='left')\n",
    "# try except to handle merge of session ids when there are no pantheon sessions\n",
    "try:\n",
    "    device_df = pd.concat([device_df, df_session_response[['session_id', 'userId', 'device.deviceId', 'device.deviceVersion', 'email']]])\n",
    "    device_df = device_df[['email','device.deviceId', 'device.deviceVersion', 'session_id']]\n",
    "except: \n",
    "    device_df = pd.concat([device_df, user_df[['userId', 'email']]])\n",
    "    device_df = device_df[['email','device.deviceId']]\n",
    "device_df = device_df.drop_duplicates()\n",
    "device_df.reset_index(inplace=True, drop=True)\n",
    "display(device_df)\n",
    "device_df.to_csv(f'device_user_pairing/device_df_{env_selection.env}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
